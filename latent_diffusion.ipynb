{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470cbc19",
   "metadata": {},
   "source": [
    "# Experiment on VAE + diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbea700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:27<00:00, 364kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 189kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.01MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE…\n",
      "epoch 1: loss=210.4685 recon=198.5951 kl=11.8734 (7.7s)\n",
      "epoch 2: loss=135.9668 recon=121.0695 kl=14.8972 (8.4s)\n",
      "epoch 3: loss=128.3153 recon=112.8967 kl=15.4186 (9.2s)\n",
      "epoch 4: loss=125.0975 recon=109.5625 kl=15.5350 (12.1s)\n",
      "epoch 5: loss=122.8360 recon=107.1942 kl=15.6418 (16.2s)\n",
      "Training latent DDPM…\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 192\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved samples to samples/mnist_ldm.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 176\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (z0,) \u001b[38;5;129;01min\u001b[39;00m z_loader:\n\u001b[1;32m    175\u001b[0m     z0 \u001b[38;5;241m=\u001b[39m z0\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 176\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     opt_diff\u001b[38;5;241m.\u001b[39mzero_grad(); loss\u001b[38;5;241m.\u001b[39mbackward(); opt_diff\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    178\u001b[0m     tot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m z0\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 111\u001b[0m, in \u001b[0;36mLatentDDPM.loss\u001b[0;34m(self, z0)\u001b[0m\n\u001b[1;32m    109\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT, (B,), device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    110\u001b[0m eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(z0)\n\u001b[0;32m--> 111\u001b[0m zt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m eps_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(zt, t)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(eps_pred, eps)\n",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m, in \u001b[0;36mLatentDDPM.add_noise\u001b[0;34m(self, z0, t, noise)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_noise\u001b[39m(\u001b[38;5;28mself\u001b[39m, z0: torch\u001b[38;5;241m.\u001b[39mTensor, t: torch\u001b[38;5;241m.\u001b[39mTensor, noise: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 104\u001b[0m     ab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malphabar\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(z0\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msqrt(ab) \u001b[38;5;241m*\u001b[39m z0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ab) \u001b[38;5;241m*\u001b[39m noise\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "# minimal latent-diffusion-on-VAE for MNIST (PyTorch)\n",
    "import math, os, random, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dim: int = 8):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.enc_fc = nn.Linear(64 * 7 * 7, 2 * z_dim)\n",
    "        self.dec_fc = nn.Linear(z_dim, 64 * 7 * 7)\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1)  # logits\n",
    "        )\n",
    "        self.z_dim = z_dim\n",
    "        self.apply(self._init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init(m: nn.Module):\n",
    "        if isinstance(m, (nn.Linear, nn.Conv2d, nn.ConvTranspose2d)):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        h = self.enc(x)\n",
    "        mu, logvar = self.enc_fc(h).chunk(2, dim=1)\n",
    "        return mu, logvar\n",
    "\n",
    "    @staticmethod\n",
    "    def reparam(mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        return mu + torch.randn_like(mu) * torch.exp(0.5 * logvar)\n",
    "\n",
    "    def decode_logits(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.dec_fc(z).view(z.size(0), 64, 7, 7)\n",
    "        return self.dec(h)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparam(mu, logvar)\n",
    "        logits = self.decode_logits(z)\n",
    "        return logits, mu, logvar\n",
    "\n",
    "def vae_loss(logits: torch.Tensor, x: torch.Tensor, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "    recon = F.binary_cross_entropy_with_logits(logits, x, reduction=\"sum\")\n",
    "    kld = 0.5 * (mu.pow(2) + logvar.exp() - logvar - 1).sum()\n",
    "    return recon + kld, recon.detach(), kld.detach()\n",
    "\n",
    "def sinusoidal_embedding(t: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    device = t.device\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(torch.linspace(math.log(1e-4), math.log(1.0), half, device=device))\n",
    "    ang = t.float()[:, None] * freqs[None, :]\n",
    "    emb = torch.cat([torch.sin(ang), torch.cos(ang)], dim=1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0,1))\n",
    "    return emb\n",
    "\n",
    "class LatentDenoiser(nn.Module):\n",
    "    def __init__(self, z_dim: int, t_dim: int = 64, h: int = 256):\n",
    "        super().__init__()\n",
    "        self.t_dim = t_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim + t_dim, h), nn.SiLU(),\n",
    "            nn.Linear(h, h), nn.SiLU(),\n",
    "            nn.Linear(h, z_dim)\n",
    "        )\n",
    "        self.apply(self._init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init(m: nn.Module):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, zt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        te = sinusoidal_embedding(t, self.t_dim)\n",
    "        return self.net(torch.cat([zt, te], dim=1))\n",
    "\n",
    "@dataclass\n",
    "class DiffusionCfg:\n",
    "    T: int = 200\n",
    "    beta_start: float = 1e-4\n",
    "    beta_end: float = 0.02\n",
    "\n",
    "class LatentDDPM:\n",
    "    def __init__(self, z_dim: int, cfg: DiffusionCfg):\n",
    "        b = torch.linspace(cfg.beta_start, cfg.beta_end, cfg.T)\n",
    "        a = 1.0 - b\n",
    "        ab = torch.cumprod(a, dim=0)\n",
    "        self.beta, self.alpha, self.alphabar = b, a, ab\n",
    "        self.T = cfg.T\n",
    "        self.model = LatentDenoiser(z_dim)\n",
    "\n",
    "    def add_noise(self, z0: torch.Tensor, t: torch.Tensor, noise: torch.Tensor) -> torch.Tensor:\n",
    "        ab = self.alphabar[t].to(z0.device)[:, None]\n",
    "        return torch.sqrt(ab) * z0 + torch.sqrt(1 - ab) * noise\n",
    "\n",
    "    def loss(self, z0: torch.Tensor) -> torch.Tensor:\n",
    "        B, device = z0.size(0), z0.device\n",
    "        t = torch.randint(0, self.T, (B,), device=device, dtype=torch.long)\n",
    "        eps = torch.randn_like(z0)\n",
    "        zt = self.add_noise(z0, t, eps)\n",
    "        eps_pred = self.model(zt, t)\n",
    "        return F.mse_loss(eps_pred, eps)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n: int, device: torch.device) -> torch.Tensor:\n",
    "        z = torch.randn(n, self.model.net[-1].out_features, device=device)\n",
    "        for t in reversed(range(self.T)):\n",
    "            tt = torch.full((n,), t, device=device, dtype=torch.long)\n",
    "            eps = self.model(z, tt)\n",
    "            a, b, ab = self.alpha[t].to(device), self.beta[t].to(device), self.alphabar[t].to(device)\n",
    "            z = (1/torch.sqrt(a))*(z - (b/torch.sqrt(1 - ab)) * eps)\n",
    "            if t > 0:\n",
    "                z = z + torch.sqrt(b) * torch.randn_like(z)\n",
    "        return z\n",
    "\n",
    "def main():\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # data\n",
    "    tfm = transforms.Compose([transforms.ToTensor()])\n",
    "    train_set = datasets.MNIST(root=\"data\", train=True, download=True, transform=tfm)\n",
    "    train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # VAE\n",
    "    vae = VAE(z_dim=8).to(device)\n",
    "    opt_vae = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "    print(\"Training VAE…\")\n",
    "    vae.train()\n",
    "    for epoch in range(5):\n",
    "        s_time, tot, rec, kl = time.time(), 0.0, 0.0, 0.0\n",
    "        for x, _ in train_loader:\n",
    "            x = x.to(device)\n",
    "            logits, mu, logvar = vae(x)\n",
    "            loss, r, k = vae_loss(logits, x, mu, logvar)\n",
    "            opt_vae.zero_grad(); loss.backward(); opt_vae.step()\n",
    "            tot += loss.item(); rec += r.item(); kl += k.item()\n",
    "        n = len(train_loader.dataset)\n",
    "        print(f\"epoch {epoch+1}: loss={tot/n:.4f} recon={rec/n:.4f} kl={kl/n:.4f} ({time.time()-s_time:.1f}s)\")\n",
    "\n",
    "    # freeze VAE, build latent dataset (use μ for stability)\n",
    "    vae.eval()\n",
    "    zs = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in DataLoader(train_set, batch_size=512):\n",
    "            mu, _ = vae.encode(x.to(device))\n",
    "            zs.append(mu.cpu())\n",
    "    z_all = torch.cat(zs)\n",
    "    z_ds = TensorDataset(z_all)\n",
    "    z_loader = DataLoader(z_ds, batch_size=512, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Diffusion in latent space\n",
    "    ddpm = LatentDDPM(z_dim=vae.z_dim, cfg=DiffusionCfg(T=200)).__dict__  # grab buffers before moving\n",
    "    diffusion = LatentDDPM(z_dim=vae.z_dim, cfg=DiffusionCfg(T=200))      # new object to hold model\n",
    "    diffusion.beta, diffusion.alpha, diffusion.alphabar = ddpm[\"beta\"], ddpm[\"alpha\"], ddpm[\"alphabar\"]\n",
    "    diffusion.model.to(device)\n",
    "    opt_diff = torch.optim.Adam(diffusion.model.parameters(), lr=2e-4)\n",
    "\n",
    "    print(\"Training latent DDPM…\")\n",
    "    for epoch in range(10):\n",
    "        s_time, tot = time.time(), 0.0\n",
    "        for (z0,) in z_loader:\n",
    "            z0 = z0.to(device)\n",
    "            loss = diffusion.loss(z0)\n",
    "            opt_diff.zero_grad(); loss.backward(); opt_diff.step()\n",
    "            tot += loss.item() * z0.size(0)\n",
    "        print(f\"epoch {epoch+1}: mse={tot/len(z_ds):.6f} ({time.time()-s_time:.1f}s)\")\n",
    "\n",
    "    # sample → decode → save\n",
    "    diffusion.model.eval()\n",
    "    with torch.no_grad():\n",
    "        z_samp = diffusion.sample(n=64, device=device)\n",
    "        x_logits = vae.decode_logits(z_samp)\n",
    "        x = torch.sigmoid(x_logits).cpu()\n",
    "        os.makedirs(\"samples\", exist_ok=True)\n",
    "        utils.save_image(x, \"samples/mnist_ldm.png\", nrow=8)\n",
    "    print(\"Saved samples to samples/mnist_ldm.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d453c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
