{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2350c80f",
   "metadata": {},
   "source": [
    "# Conv ResNet\n",
    "\n",
    "we are applying tucker compression for mode-0 and mode-1 (Channel in and channel out).\n",
    "\n",
    "suppose $\\mathbf{W} \\in \\mathbb{R}^{C_{out} \\times C_{in} \\times k_{h} \\times k_{w}}$ is a 2D \n",
    "\n",
    "Let \n",
    "$\\mathbf{X}^{(0)} \\in \\mathbb{R}^{C_{in} \\times H_{in} \\times W_{in}}$ : input feature map\n",
    "\n",
    "therefore, we perform tucker decomposition:\n",
    "$$\\mathbf{W} \\approx \\mathbf{S} \\times_{0} U^{(0)} \\times_{1}U^{(1)}$$\n",
    "where:\n",
    "$U^{(0)} \\in \\mathbb{R}^{C_{out} \\times r_{0}}$ : output (channel) basis\n",
    "$U^{(1)} \\in \\mathbb{R}^{C_{in} \\times r_{1}}$ : input (channel) basis\n",
    "$\\mathbf{S} \\in \\mathbb{R}^{r_{0} \\times r_{1} \\times k_{h} \\times k_{w}}$ : compressed core kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53916fb0",
   "metadata": {},
   "source": [
    "## 1. reduce channels\n",
    "from $C_{in} \\rightarrow r_{0}$ using mode-1 multiplication\n",
    "$$\\mathbf{X}^{(1)} = U^{(1)\\intercal} \\times_{1} \\mathbf{X}^{(0)}\\quad \\in \\mathbb{R}^{r_{1} \\times H_{in} \\times W_{in}}$$\n",
    "which is equivalent to $1\\times 1$ convolution with weight $U^{(1)\\intercal} \\in \\mathbb{R}^{r_{1} \\times C_{in}}$\n",
    "\n",
    "## 2. spatial convolution with core\n",
    "$$\\mathbf{X}^{(2)} = \\mathbf{S} * \\mathbf{X}^{(1)} \\quad \\in \\mathbb{R}^{r_{0} \\times H_{out} \\times W_{out}}$$\n",
    "convolution using the compressed core\n",
    "$\\mathbf{S} \\in \\mathbb{R}^{r_{0} \\times r_{1} \\times k_{h} \\times k_{w}}$\n",
    "\n",
    "## 3. expand channels\n",
    "From $r_{0} \\rightarrow C_{out}$ using mode-0 multiplication\n",
    "$$\n",
    "\\mathbf{Y} = U^{(0)} \\times_{1} \\mathbf{X}^{(2)} \\quad \\in \\mathbb{R}^{C_{out} \\times H_{out} \\times W_{out}}\n",
    "$$\n",
    "\n",
    "\n",
    "**therefore**\n",
    "$$\\mathbf{Y} \\approx U^{(0)} \\cdot \\left(  \\mathbf{S} * \\left( U^{(1)\\intercal} \\cdot \\mathbf{X}^{(0)} \\right)   \\right) $$\n",
    "\n",
    "this reduces cost \n",
    "from: $\\mathcal{O}(C_{out} \\cdot  C_{in} \\cdot H \\cdot W)$\n",
    "to: $\\mathcal{O}(C_{out} r_{0} + r_{0}r_{1}  H W + r_{1} C_{in})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-100 ImageFolder already prepared.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f4e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "from src.logger import setup_logger\n",
    "\n",
    "\n",
    "class TuckerCompressor:\n",
    "    def __init__(self) -> None:\n",
    "        self.logger = setup_logger(\"api.log\")\n",
    "\n",
    "    def compress_conv2d(\n",
    "        self,\n",
    "        conv: nn.Conv2d,\n",
    "        rank: Tuple[int, int]\n",
    "    ) -> nn.Sequential:\n",
    "        \"\"\"Compress a Conv2d layer using Tucker decomposition (mode-0 and mode-1).\"\"\"\n",
    "        C_out, C_in = conv.out_channels, conv.in_channels\n",
    "        kh, kw = conv.kernel_size\n",
    "        stride, padding, dilation = conv.stride, conv.padding, conv.dilation\n",
    "        r_out, r_in = rank\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"Compressing Conv2d: Cin={C_in}, Cout={C_out}, kh={kh}, kw={kw}, rank={rank}\"\n",
    "        )\n",
    "\n",
    "        weight = conv.weight.data  # (C_out, C_in, kh, kw)\n",
    "        weight_unfold_0 = weight.reshape(C_out, -1)\n",
    "        weight_unfold_1 = weight.permute(1, 0, 2, 3).reshape(C_in, -1)\n",
    "\n",
    "        U_0, _, _ = torch.linalg.svd(weight_unfold_0, full_matrices=False)\n",
    "        U_1, _, _ = torch.linalg.svd(weight_unfold_1, full_matrices=False)\n",
    "\n",
    "        U_0_tilde = U_0[:, :r_out]  # (C_out, r_out)\n",
    "        U_1_tilde = U_1[:, :r_in]   # (C_in, r_in)\n",
    "\n",
    "        # Compute core tensor: W ×₀ U₀ᵀ ×₁ U₁ᵀ\n",
    "        core = torch.einsum('oc, cihw -> oihw', U_0_tilde.T, weight)\n",
    "        core = torch.einsum('ci, oihw -> ochw', U_1_tilde.T, core)\n",
    "\n",
    "\n",
    "        first_1x1 = nn.Conv2d(\n",
    "            in_channels=C_in,\n",
    "            out_channels=r_in,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        core_conv = nn.Conv2d(\n",
    "            in_channels=r_in,\n",
    "            out_channels=r_out,\n",
    "            kernel_size=(kh, kw),\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        last_1x1 = nn.Conv2d(\n",
    "            in_channels=r_out,\n",
    "            out_channels=C_out,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            first_1x1.weight.copy_(U_1_tilde.T.unsqueeze(-1).unsqueeze(-1))\n",
    "            core_conv.weight.copy_(core)\n",
    "            if conv.bias is not None:\n",
    "                last_1x1.bias.copy_(conv.bias)\n",
    "            last_1x1.weight.copy_(U_0_tilde.unsqueeze(-1).unsqueeze(-1))\n",
    "\n",
    "        return nn.Sequential(first_1x1, core_conv, last_1x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0121a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "from src.logger import setup_logger\n",
    "\n",
    "\n",
    "logger = setup_logger(\"tucker_eval.log\")\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(data_root: str, batch_size: int = 128, num_workers: int = 4):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_set = datasets.ImageFolder(root=f\"{data_root}/train\", transform=transform_train)\n",
    "    val_set = datasets.ImageFolder(root=f\"{data_root}/val\", transform=transform_test)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, dataloader: DataLoader, device: torch.device) -> float:\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def fine_tune(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, device: torch.device,\n",
    "              epochs: int = 5, lr: float = 0.01):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=lr, momentum=0.9, weight_decay=5e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        logger.info(f\"Fine-tune Epoch {epoch+1}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "\n",
    "def compress_model(model: nn.Module, ratio: float = 0.2) -> nn.Module:\n",
    "    compressor = TuckerCompressor()\n",
    "\n",
    "    def compress_layer(module: nn.Module):\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                r_out = max(1, int(child.out_channels * ratio))\n",
    "                r_in = max(1, int(child.in_channels * ratio))\n",
    "                setattr(module, name, compressor.compress_conv2d(child, rank=(r_out, r_in)))\n",
    "            else:\n",
    "                compress_layer(child)\n",
    "\n",
    "    model = copy.deepcopy(model)\n",
    "    compress_layer(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_resnet18_100_classes():\n",
    "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 100)  # 100 CIFAR-100 classes\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 782/782 [04:36<00:00,  2.83it/s]\n",
      "2025-04-09 16:27:35,987 - INFO - Fine-tune Epoch 1, Accuracy: 0.4408\n",
      "Epoch 2/5: 100%|██████████| 782/782 [03:40<00:00,  3.54it/s]\n",
      "2025-04-09 16:32:12,038 - INFO - Fine-tune Epoch 2, Accuracy: 0.4781\n",
      "Epoch 3/5: 100%|██████████| 782/782 [04:18<00:00,  3.02it/s]\n",
      "2025-04-09 16:37:27,021 - INFO - Fine-tune Epoch 3, Accuracy: 0.5105\n",
      "Epoch 4/5: 100%|██████████| 782/782 [09:17<00:00,  1.40it/s]\n",
      "2025-04-09 16:48:27,710 - INFO - Fine-tune Epoch 4, Accuracy: 0.5108\n",
      "Epoch 5/5: 100%|██████████| 782/782 [05:28<00:00,  2.38it/s]\n",
      "2025-04-09 16:55:04,072 - INFO - Fine-tune Epoch 5, Accuracy: 0.5196\n",
      "2025-04-09 16:55:04,076 - INFO - Finished finetuning original model in 1964.6274065971375s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# 1) Setup\n",
    "train_loader, test_loader = get_dataloader(\n",
    "    data_root=dataset_path, \n",
    "    batch_size=64, \n",
    "    num_workers=4\n",
    "    )\n",
    "model = get_resnet18_100_classes().to(device)\n",
    "\n",
    "t0 = time.time()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "fine_tune(model, train_loader, test_loader, device, epochs=5)\n",
    "logger.info(f\"Finished finetuning original model in {time.time() - t0:.4f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c91165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:56:18,613 - INFO - Original ResNet18 Accuracy: 0.5196\n",
      "2025-04-09 16:56:18,615 - INFO - Evaluated in 40.9793s\n"
     ]
    }
   ],
   "source": [
    "# 2) Evaluate_original\n",
    "t0 = time.time()\n",
    "original_acc = evaluate(model, test_loader, device)\n",
    "logger.info(f\"Original ResNet18 Accuracy: {original_acc:.4f}\")\n",
    "logger.info(f\"Evaluated in {time.time() - t0:.4f}s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2326e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:56:51,632 - INFO - Logger already initialized\n",
      "2025-04-09 16:56:51,664 - INFO - Compressing Conv2d: Cin=3, Cout=64, kh=7, kw=7, rank=(12, 1)\n",
      "2025-04-09 16:56:51,759 - INFO - Compressing Conv2d: Cin=64, Cout=64, kh=3, kw=3, rank=(12, 12)\n",
      "2025-04-09 16:56:51,767 - INFO - Compressing Conv2d: Cin=64, Cout=64, kh=3, kw=3, rank=(12, 12)\n",
      "2025-04-09 16:56:51,774 - INFO - Compressing Conv2d: Cin=64, Cout=64, kh=3, kw=3, rank=(12, 12)\n",
      "2025-04-09 16:56:51,780 - INFO - Compressing Conv2d: Cin=64, Cout=64, kh=3, kw=3, rank=(12, 12)\n",
      "2025-04-09 16:56:51,787 - INFO - Compressing Conv2d: Cin=64, Cout=128, kh=3, kw=3, rank=(25, 12)\n",
      "2025-04-09 16:56:51,797 - INFO - Compressing Conv2d: Cin=128, Cout=128, kh=3, kw=3, rank=(25, 25)\n",
      "2025-04-09 16:56:51,809 - INFO - Compressing Conv2d: Cin=64, Cout=128, kh=1, kw=1, rank=(25, 12)\n",
      "2025-04-09 16:56:51,816 - INFO - Compressing Conv2d: Cin=128, Cout=128, kh=3, kw=3, rank=(25, 25)\n",
      "2025-04-09 16:56:51,829 - INFO - Compressing Conv2d: Cin=128, Cout=128, kh=3, kw=3, rank=(25, 25)\n",
      "2025-04-09 16:56:51,842 - INFO - Compressing Conv2d: Cin=128, Cout=256, kh=3, kw=3, rank=(51, 25)\n",
      "2025-04-09 16:56:51,874 - INFO - Compressing Conv2d: Cin=256, Cout=256, kh=3, kw=3, rank=(51, 51)\n",
      "2025-04-09 16:56:51,926 - INFO - Compressing Conv2d: Cin=128, Cout=256, kh=1, kw=1, rank=(51, 25)\n",
      "2025-04-09 16:56:51,937 - INFO - Compressing Conv2d: Cin=256, Cout=256, kh=3, kw=3, rank=(51, 51)\n",
      "2025-04-09 16:56:51,986 - INFO - Compressing Conv2d: Cin=256, Cout=256, kh=3, kw=3, rank=(51, 51)\n",
      "2025-04-09 16:56:52,035 - INFO - Compressing Conv2d: Cin=256, Cout=512, kh=3, kw=3, rank=(102, 51)\n",
      "2025-04-09 16:56:52,160 - INFO - Compressing Conv2d: Cin=512, Cout=512, kh=3, kw=3, rank=(102, 102)\n",
      "2025-04-09 16:56:52,387 - INFO - Compressing Conv2d: Cin=256, Cout=512, kh=1, kw=1, rank=(102, 51)\n",
      "2025-04-09 16:56:52,418 - INFO - Compressing Conv2d: Cin=512, Cout=512, kh=3, kw=3, rank=(102, 102)\n",
      "2025-04-09 16:56:52,645 - INFO - Compressing Conv2d: Cin=512, Cout=512, kh=3, kw=3, rank=(102, 102)\n",
      "2025-04-09 16:56:52,878 - INFO - Model compressed in 1.2459s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Compress_model\n",
    "t0 = time.time()\n",
    "compressed_model = compress_model(model, ratio=0.2)\n",
    "compressed_model.to(device)\n",
    "logger.info(f\"Model compressed in {time.time() - t0:.4f}s\")\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1851af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:57:28,796 - INFO - Compressed ResNet18 (no fine-tune) Accuracy: 0.0096\n",
      "2025-04-09 16:57:28,799 - INFO - Evaluated in 37.1672s\n"
     ]
    }
   ],
   "source": [
    "# 4) Evaluate_compressing\n",
    "compressed_acc = evaluate(compressed_model, test_loader, device)\n",
    "logger.info(f\"Compressed ResNet18 (no fine-tune) Accuracy: {compressed_acc:.4f}\")\n",
    "logger.info(f\"Evaluated in {time.time() - t0:.4f}s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7254dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 782/782 [10:28<00:00,  1.24it/s]\n",
      "2025-04-09 17:09:13,088 - INFO - Fine-tune Epoch 1, Accuracy: 0.2414\n",
      "Epoch 2/5: 100%|██████████| 782/782 [11:14<00:00,  1.16it/s]\n",
      "2025-04-09 17:21:33,421 - INFO - Fine-tune Epoch 2, Accuracy: 0.3454\n",
      "Epoch 3/5: 100%|██████████| 782/782 [14:07<00:00,  1.08s/it]\n",
      "2025-04-09 17:37:00,586 - INFO - Fine-tune Epoch 3, Accuracy: 0.5040\n",
      "Epoch 4/5: 100%|██████████| 782/782 [15:39<00:00,  1.20s/it]\n",
      "2025-04-09 17:54:00,698 - INFO - Fine-tune Epoch 4, Accuracy: 0.5178\n",
      "Epoch 5/5: 100%|██████████| 782/782 [11:25<00:00,  1.14it/s]\n",
      "2025-04-09 18:06:38,770 - INFO - Fine-tune Epoch 5, Accuracy: 0.5336\n",
      "2025-04-09 18:06:38,773 - INFO - Finetuned in 4133.8973s\n"
     ]
    }
   ],
   "source": [
    "# 5) fine_tune\n",
    "t0 = time.time()\n",
    "fine_tune(compressed_model, train_loader, test_loader, device, epochs=5)\n",
    "logger.info(f\"Finetuned in {time.time() - t0:.4f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c53c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 18:07:57,728 - INFO - Compressed + Fine-Tuned ResNet18 Accuracy: 0.5336\n",
      "2025-04-09 18:07:57,729 - INFO - Evaluated in 27.3281s\n"
     ]
    }
   ],
   "source": [
    "# 6) evaluate finetuned\n",
    "t0 = time.time()\n",
    "final_acc = evaluate(compressed_model, test_loader, device)\n",
    "logger.info(f\"Compressed + Fine-Tuned ResNet18 Accuracy: {final_acc:.4f}\")\n",
    "logger.info(f\"Evaluated in {time.time() - t0:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660de34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
